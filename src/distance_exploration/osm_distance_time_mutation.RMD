---
title: "OSM Time-Distance Mutation"
author: "DSPG Business Innovation Team"
date: "7/15/2019"
output: 
  github_document: default
  html_document: default
---

```{r setup, include=FALSE, message = FALSE, warning = FALSE}
#Setting root directory
knitr::opts_knit$set(echo = TRUE,
                     root.dir = rprojroot::find_rstudio_root_file())

#Load Pacman for multiple package loads
if (!require("pacman")) install.packages(pacman)

#Need most updated dplyr if haven't already done this
#install.packages("dplyr") #need updated dplyr for sf objects

#Load all the good stuff
pacman::p_load(tidyverse, purrr, sf, sp, mapview, ggmap,
               patchwork, osmdata, mapview, traveltime,
               iterators, doParallel, foreach, parallel,
               geosphere, rgeos, raster, RapidPolygonLookup)

#Controlling figure output in markdown
knitr::opts_chunk$set(
#  fig.height =   
  fig.width = 6,
#  fig.asp = .5,
  out.width = "90%",
#  out.height = 
  cache = TRUE
)

#Set Theme for ggplot2
theme_set(theme_bw() + theme(plot.title = element_text(hjust = 0.5), legend.position = "bottom"))

#Set Scientific notation output for knitr
options(scipen = 999999)
```

##1. Read and Verify

```{r}
#Source of Data
relative.path <- "./data/working/Time_distance_files/raw_time_distance_lists"

#Read/Tidy .RDS Time-Distance list of `sf` objects
osm.df <- list.files(relative.path) %>%
  enframe() %>%
  rename(path = value) %>%
  mutate(
    name = str_split(path, ".rds") %>% 
           map(1) %>%
           unlist(),
    path = str_c(relative.path, "/", path),
    data = map(.x = path, ~read_rds(.x) %>%
                           do.call(rbind.data.frame, .) %>%
                           as_tibble())
    )
```


####Number of Observations  


```{r}
#Check Number of Observations per Name
n.obs <- osm.df$data %>% map_dbl(., nrow)
names(n.obs) <- osm.df$name

#Visualize
enframe(n.obs) %>%
  rename(observations = value) %>%
  knitr::kable()
```


Verify with original data for number of observations. 
```{r warning = FALSE, message = FALSE}
#Compare with Original OSM data
osm.orig.df   <- read_csv("./data/working/OSM_joined/7_10_2019_osm_joined.csv") %>%
  filter(variable != "Park")

#Number of obs. for each variable
table(osm.orig.df$variable)
```



Number of observations, points in the original data and `sf` objects in the time-distance data, appears to be correct. Next we check if there are `NULL`, `NA`, or empty values for our geometries (the polygon boundary geospatial data points).  

####Missing Values  

```{r}
#Empty Geometries
n.empty <- osm.df$data %>% 
  map("geometry") %>%
  map(attributes) %>%
  map_dbl("n_empty") %>%
  sum()

#Zero Empty Geometries
```  


There are `r n.empty` missing geometries within these data.  

##2. Calulate Binary Yes/No Fairfax Domocile in Polygon

Here we are mapping over each variable (Playground, Sports Centers, Etc.). Extract polygon boundary lat long from `sf` objects, store as data frame.  

```{r}
#Function to extract Lat Long
lat.long <- function(osm_polygons) {
    st_coordinates(osm_polygons) %>%
      as_tibble() %>%
      rename(
        longitude = X,
        latitude  = Y,
        object_id = L3
      ) %>%
    dplyr::select(longitude, latitude)
}

#Function to replace sf with data frame of id, long, and lat
osm.lat.long.df <- osm.df %>%
  mutate(
    data = map(.x = data, 
               ~ .x %>% 
                 mutate(geometry = map(geometry, lat.long)) %>%
                 dplyr::select(geometry) %>%
                 mutate(id = 1:nrow(.x) %>% as.factor())
              )
  )

make_SPDF <- function(osm.data) {
      #Grab the Poly ID's
      id <- osm.data$id
      #Transform RAW lat long for all objects into SPDF
      osm.data$geometry %>%
               map(.x = .,
                   ~ .x %>%
                     dplyr::select(longitude, latitude) %>%
                     as.matrix() %>%
                     Polygon()) %>%
               map(list) %>%
               map2(.x = ., .y = id, ~Polygons(.x, ID = .y)) %>%
               SpatialPolygons() %>%
               SpatialPolygonsDataFrame(., data.frame(id = id))
      #Outputs an sp object of class SpatialPolygonsDataFrame
}

#Make a new data frame where the data is a list of SPDF objects corresponding to the Time-Distance Polygons by Variable
osm.spdf <- osm.lat.long.df %>%
            mutate(
              data = map(.x = data, ~make_SPDF(.x))
            )

##Store for later
#write_rds(osm.spdf, "./data/working/Time_distance_files/time_distance_spdf.RDS")
```

Read in the Time-Distance OSM .RDS file and the Fairfax Housing stock data.  

```{r message = FALSE}
#Time Distance OSM lat long
osm.df <- read_rds("./data/working/Time_distance_files/time_dist_spdf.RDS")

#Fairfax Housing
ffx.df  <- read_csv("./data/working/Fairfax_Housing_2018/fairfax_housing_2018_geo.csv") %>%
  janitor::clean_names()

#Figure out How to Calculate Point in Polygon 
```



#Testing RGEOS
```{r}
#Test out RapidPolygonLookup
lat.long.df <- ffx.df %>%
  dplyr::select(longitude, latitude)

#Get fairfax boundary box
ff.boundary <- getbb("fairfax county")

#Test out RapidPolygonFunction on one variable's set of sf time-distance polygons
osm.sf.df$data[[1]]$geometry %>% st_sf() %>% as_Spatial(from = ., cast = FALSE)

osm.sf.df$data[[1]]$geometry %>% st_set_crs(CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0")) %>% as(., "Spatial")

pts <- st_sf(a=3, st_sfc(st_point(1:2)))
sp_pts <- as(pts, "Spatial")
as(st_geometry(pts), "Spatial")


class(pts)
class(st_geometry(pts))
class(sp_pts)

CropSpatialPolygonsDataFrame(x= osm.sf.df$data[[1]]$geometry[1],
  bb= data.frame(X=c(-122.5132, -122.37),
  Y= c(37.70760, 37.81849)))

##  First project data into a planar coordinate system (here UTM zone 32)
a <- Sys.time()
point.in.polygon(osm.orig.df[1, ]$longitude,
                 osm.orig.df[1, ]$latitude,
                 osm.df$data[[1]]$geometry[[1]]$longitude,
                 osm.df$data[[1]]$geometry[[1]]$latitude)
b <- Sys.time()

b - a


```
